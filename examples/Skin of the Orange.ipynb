{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin of the Orange\n",
    "**PAGE 431.** We generated 100 observations in each of two classes. The first class has four standard normal independent features $X_1, X_2, X_3, X_4$. The second class also has four standard normal independent features, but conditioned on $9 \\le \\sum X_j^2 \\le 16$. This is relatively easy problem. As a second harder problem, we augmented the features with an additional six standard Gaussian noise features. Hence the second class almost completely surrounds the first, like the skin surrounding the orange, in a four-dimensional subspace.\n",
    "\n",
    "**DATA INFO.** There are two datasets. The first is non-noise features situation. The second is six-noise features situation. There are 50 simulations for each case. One simulation has 100 training records and 1000 test records. \n",
    "\n",
    "|           |            |\n",
    "|-----------|------------|\n",
    "|column 0    |simulation id (from 0 to 49)|\n",
    "|column 1    |train/test flag (0 for training)|\n",
    "|column 2    |class id -1/1|\n",
    "|columns 3-6 |features|\n",
    "|*columns 7-12 |noise (for the secod case)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded = np.load('../data/orange.npz')\n",
    "no_noise_ds, six_noise_ds = loaded['no_noise'], loaded['six_noise']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Error Rate\n",
    "We know the underlying distribution of the data, so let's compute the error rate on the whole test data using optimal Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029\n"
     ]
    }
   ],
   "source": [
    "ds = np.vstack((no_noise_ds, six_noise_ds[:, :7]))\n",
    "# find the test records\n",
    "records = ds[(ds[:, 1] == 1), :]\n",
    "# use only 3-7 features, the other features contain noise\n",
    "features = records[:, 3:7]\n",
    "# score actually is the squared distance from zero\n",
    "score = np.sum(features**2, axis=1)\n",
    "# classifiy to -1 if it is the second class\n",
    "y_hat = 1 - 2*((score <= 16) & (score >= 9))\n",
    "bayes_error_rate = 1 - accuracy_score(records[:, 2], y_hat)\n",
    "# PAGE 431. The Bayes error rate for this problem is 0.029\n",
    "#           (irrespective of dimension).\n",
    "print(f'{bayes_error_rate:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_svc_on_data(ds, **kwargs):\n",
    "    \"\"\"Estimates mean error rate and its standard error of the SVC algorithm\n",
    "       on a provided dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : a dataset with training and test data for 50 simulations\n",
    "    kwargs : parameters for the Support Vector Classifier\n",
    "    Returns\n",
    "    -------\n",
    "    mean_error : mean test error rate based on 50 simulations\n",
    "    mean_error_std : standard error of the mean test error rate\n",
    "    \"\"\"\n",
    "    error_rates = np.zeros(50)\n",
    "    # PAGE 431. The average test errors over 50 simulations, with and without\n",
    "    #           noise features, are shown in Table 12.2.\n",
    "    for sim_id in range(50):\n",
    "        train_ds = ds[(ds[:, 0] == sim_id) & (ds[:, 1] == 0), :]\n",
    "        test_ds = ds[(ds[:, 0] == sim_id) & (ds[:, 1] == 1), :]\n",
    "        best_err, best_C = 1, 0\n",
    "        # PAGE 431. For all support vector procedures, we chose the cost\n",
    "        #           parameter C to minimize the test error, to be as fair\n",
    "        #           as possible to the method.\n",
    "        for C in np.linspace(0.01, 5, 20):\n",
    "            err = 1 - SVC(C=C, max_iter=100000, **kwargs).fit(\n",
    "                train_ds[:, 3:], train_ds[:, 2]\n",
    "            ).score(test_ds[:, 3:], test_ds[:, 2])\n",
    "            if err < best_err:\n",
    "                best_err, best_C = err, C\n",
    "        error_rates[sim_id] = best_err\n",
    "    return np.mean(error_rates), np.std(error_rates)/np.sqrt(50)\n",
    "\n",
    "\n",
    "def estimate_svc_without_and_with_noise(**kwargs):\n",
    "    \"\"\"Estimates mean error rate and its standard error of the SVC algorithm\n",
    "       on 1) the dataset with 4 no-noise features; 2) on the dataset with 6\n",
    "       additional noise features. So, it shows how noise features affect\n",
    "       SVC performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kwargs : parameters for the Support Vector Classifier\n",
    "    Returns\n",
    "    -------\n",
    "    no_noise_mean_error : mean test error rate based on 50 simulations without\n",
    "                          noise features\n",
    "    no_noise_mean_error_std : standard error of the mean test error rate\n",
    "                              without noise features\n",
    "    noise_mean_error : mean test error rate based on 50 simulations with noise\n",
    "                       features\n",
    "    noise_mean_error_std : standard error of the mean test error rate with\n",
    "                           noise features\n",
    "    \"\"\"\n",
    "    no_noise_err, no_noise_std = estimate_svc_on_data(no_noise_ds, **kwargs)\n",
    "    six_noise_err, six_noise_std = estimate_svc_on_data(six_noise_ds, **kwargs)\n",
    "    return no_noise_err, no_noise_std, six_noise_err, six_noise_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_svc_results = estimate_svc_without_and_with_noise(kernel='linear')\n",
    "poly2_svc_results = estimate_svc_without_and_with_noise(\n",
    "    gamma='scale', kernel='poly', coef0=1, degree=2)\n",
    "poly5_svc_results = estimate_svc_without_and_with_noise(\n",
    "    gamma='scale', kernel='poly', coef0=1, degree=5)\n",
    "poly10_svc_results = estimate_svc_without_and_with_noise(\n",
    "    gamma='scale', kernel='poly', coef0=1, degree=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyearth import Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_mars_on_data(ds):\n",
    "    \"\"\"Estimates mean error rate and its standard error of the MARS algorithm\n",
    "       on a provided dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : a dataset with training and test data for 50 simulations\n",
    "    Returns\n",
    "    -------\n",
    "    mean_error : mean test error rate based on 50 simulations\n",
    "    mean_error_std : standard error of the mean test error rate\n",
    "    \"\"\"\n",
    "    error_rates = np.zeros(50)\n",
    "    for sim_id in range(50):\n",
    "        train_ds = ds[(ds[:, 0] == sim_id) & (ds[:, 1] == 0), :]\n",
    "        test_ds = ds[(ds[:, 0] == sim_id) & (ds[:, 1] == 1), :]\n",
    "        mars = Earth(\n",
    "            max_terms=20, max_degree=4, enable_pruning=True\n",
    "        ).fit(train_ds[:, 3:], train_ds[:, 2])\n",
    "        y_hat = np.sign(mars.predict(test_ds[:, 3:]))\n",
    "        error_rates[sim_id] = 1 - accuracy_score(test_ds[:, 2], y_hat)\n",
    "    return np.mean(error_rates), np.std(error_rates)/np.sqrt(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_results = (*estimate_mars_on_data(no_noise_ds),\n",
    "                *estimate_mars_on_data(six_noise_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Test Error (SE)\n",
      "Methods           No Noise Features   Six Noise Features\n",
      "----------------------------------------------------------\n",
      "1  SV Classifier    0.449 (0.002)       0.469 (0.003)\n",
      "2  SVM/poly 2       0.075 (0.003)       0.165 (0.004)\n",
      "3  SVM/poly 5       0.130 (0.004)       0.213 (0.004)\n",
      "4  SVM/poly 10      0.179 (0.004)       0.346 (0.003)\n",
      "6  MARS             0.144 (0.005)       0.161 (0.005)\n",
      "Bayes                   0.029               0.029\n"
     ]
    }
   ],
   "source": [
    "# PAGE 431. TABLE 12.2. Skin of the orange: Shown are mean (standard error of\n",
    "#           the mean) of the test error over 50 simulations. BRUTO fits an\n",
    "#           additive spline model adaptively, while MARS fits a low-order\n",
    "#           interaction model adaptively.\n",
    "names = ['1  SV Classifier', '2  SVM/poly 2', '3  SVM/poly 5',\n",
    "         '4  SVM/poly 10', '6  MARS']\n",
    "results = [linear_svc_results, poly2_svc_results, poly5_svc_results,\n",
    "           poly10_svc_results, mars_results]\n",
    "\n",
    "print('                             Test Error (SE)')\n",
    "print('Methods           No Noise Features   Six Noise Features')\n",
    "print('----------------------------------------------------------')\n",
    "for name, result in zip(names, results):\n",
    "    no_noise_err, no_noise_std, noise_err, noise_std = result\n",
    "    print(f'{name:<20}{no_noise_err:>.3f} ({no_noise_std:.3f})'\n",
    "          f'       {noise_err:.3f} ({noise_std:.3f})')\n",
    "print(f'Bayes {bayes_error_rate:>23.3f} {bayes_error_rate:>19.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python64]",
   "language": "python",
   "name": "conda-env-Python64-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
